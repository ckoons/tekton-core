component:
  id: rhetor
  name: Rhetor
  version: 0.1.0
  description: LLM management and communication engine for Tekton
  port: 8003

capabilities:
  - id: llm_management
    name: LLM Management
    description: Centralized management of LLM interactions
    methods:
      - id: invoke
        name: Invoke LLM
        description: Send a prompt to an LLM and receive a response
        parameters:
          - name: prompt
            type: string
            required: true
            description: The prompt to send to the LLM
          - name: model
            type: string
            required: false
            description: The LLM model to use
            default: default
          - name: temperature
            type: number
            required: false
            description: The temperature to use for generation
            default: 0.7
          - name: max_tokens
            type: number
            required: false
            description: The maximum number of tokens to generate
            default: 1024
        returns:
          type: string
          description: The LLM response

      - id: stream
        name: Stream LLM Response
        description: Stream responses from an LLM
        parameters:
          - name: prompt
            type: string
            required: true
            description: The prompt to send to the LLM
          - name: model
            type: string
            required: false
            description: The LLM model to use
            default: default
          - name: temperature
            type: number
            required: false
            description: The temperature to use for generation
            default: 0.7
          - name: max_tokens
            type: number
            required: false
            description: The maximum number of tokens to generate
            default: 1024
        returns:
          type: stream
          description: Stream of LLM response chunks

  - id: prompt_management
    name: Prompt Management
    description: Management of prompt templates and registries
    methods:
      - id: get_template
        name: Get Prompt Template
        description: Get a prompt template by ID
        parameters:
          - name: template_id
            type: string
            required: true
            description: The ID of the template to get
        returns:
          type: object
          description: The prompt template

      - id: render_template
        name: Render Prompt Template
        description: Render a prompt template with variables
        parameters:
          - name: template_id
            type: string
            required: true
            description: The ID of the template to render
          - name: variables
            type: object
            required: true
            description: The variables to use for rendering
        returns:
          type: string
          description: The rendered prompt

  - id: context_management
    name: Context Management
    description: Management of conversation context
    methods:
      - id: create_context
        name: Create Context
        description: Create a new conversation context
        parameters:
          - name: context_id
            type: string
            required: false
            description: The ID to assign to the context
        returns:
          type: string
          description: The ID of the created context
      
      - id: add_to_context
        name: Add to Context
        description: Add content to a conversation context
        parameters:
          - name: context_id
            type: string
            required: true
            description: The ID of the context to add to
          - name: content
            type: string
            required: true
            description: The content to add to the context
          - name: role
            type: string
            required: false
            description: The role of the content (user, assistant, system)
            default: user
        returns:
          type: boolean
          description: Whether the content was added successfully

config:
  default_model: claude-3-sonnet-20240229
  cache_enabled: true
  max_context_length: 100000
  logging_level: info